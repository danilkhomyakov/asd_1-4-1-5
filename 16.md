# Perceptions of self and other: Social judgments and gaze patterns to videos of adolescents with and without autism spectrum disorder 

Autism<br>2019, Vol. 23(4) 846-857<br>(c) The Author(s) 2018<br>Article reuse guidelines:<br>sagepub.com/journals-permissions<br>DOI: $10.1177 / 362361318788071$ journals.sagepub.com/home/aut (D) SAGE

## Ruth B Grossman ${ }^{1,2}$, Julia Mertens ${ }^{1}$ and Emily Zane ${ }^{1}$


#### Abstract

Neurotypical adults often form negative first impressions of individuals with autism spectrum disorder and are less interested in engaging with them socially. In contrast, individuals with autism spectrum disorder actively seek out the company of others who share their diagnosis. It is not clear, however, whether individuals with autism spectrum disorder form more positive first impressions of autistic peers when diagnosis is not explicitly shared. We asked adolescents with and without autism spectrum disorder to watch brief video clips of adolescents with and without autism spectrum disorder and answer questions about their impressions of the individuals in the videos. Questions were related to participants' perceptions of the social skills of the individuals in the video, as well as their own willingness to interact with that person. We also measured gaze patterns to the faces, eyes, and mouths of adolescents in the video stimuli. Both participant groups spent less time gazing at videos of autistic adolescents. Regardless of diagnostic group, all participants provided more negative judgments of autistic than neurotypical adolescents in the videos. These data indicate that, without being explicitly informed of a shared diagnosis, adolescents with autism spectrum disorder form negative first impressions of autistic adolescents that are similar to, or lower than, those formed by neurotypical peers.


## Keywords

autism spectrum disorders, communication and language, social cognition and social behavior

Individuals with autism spectrum disorder ${ }^{1}$ (ASD) have significant difficulties with social relatedness and often experience high rates of loneliness, depression, and even suicidal ideation (Berns, 2016). Even those on the autism spectrum who have preserved cognitive and language skills are frequently subjected to bullying and are often unemployed, under-employed, or unable to complete secondary education (Maïano et al., 2016; Schroeder et al., 2014; Taylor and Seltzer, 2011). In recent years, there has been an increased awareness that these interactional difficulties are not founded exclusively on the social communication difficulties of individuals with ASD. Rather, there is often a breakdown in reciprocity between social parners-those with and those without ASD-who do not share the same understanding or interpretation of social rules and behavior (Milton, 2012).

A likely starting point for this breakdown has been proposed in recent research showing that neurotypical (NT) adults and children form negative judgments of individuals
with ASD within mere seconds of exposure (Faso et al., 2015; Grossman, 2015; Sasson et al., 2017). Even individuals with ASD who have typical language and cognitive abilities are subject to such judgments. In fact, autistic individuals who have preserved cognitive and language skills often report higher levels of stigmatization, possibly because they "look" typical, but are not (Shtayermman, 2009). For instance, Stagg et al. (2014) showed NT children deciding that children with ASD were undesirable social partners after a single exposure. This type of negative first impression could lead to lasting social exclusion

[^0]
[^0]:    ${ }^{1}$ Emerson College, USA
    ${ }^{2}$ University of Massachusetts Medical School, USA

    ## Corresponding author:

    Ruth B Grossman, Department of Communication Sciences \& Disorders, Emerson College, 120 Boylston Street, Boston, MA 021 I6, USA.
    Email: ruth_grossman@emerson.edu

of individuals with ASD (Iobst et al., 2009; Swaim and Morgan, 2001).

In recent years, a growing number of online and inperson communities have been established where autistic individuals can interact (Komeda, 2015). Members of these communities often report a sense of shared identity and shared traits, sometimes expressed as coming from the "same planet" (Sinclair, 2010). This suggests that individuals with ASD may prefer the company of one another to the company of NT individuals. However, these communities are created with the explicit knowledge that all members share the same diagnostic status. Recent evidence shows that knowledge of an ASD diagnosis leads to more positive perceptions by others (Sasson and Morrison, 2017). Without this explicit knowledge, it is unclear whether autistic individuals form more favorable first impressions of each other than those formed by NT peers. Without being explicitly informed of a shared diagnosis, do social signals of unfamiliar individuals with ASD reduce the possibility of interactions with other autistic peers, similar to the effect seen for impressions formed by NT peers?

Although there are many factors that can influence first impressions, such as body posture and gestures (Ambady and Skowronski, 2008), we focus our investigation on how individuals with ASD process social information from two highly salient sources: facial and vocal expressions. The evidence on face processing is mixed, with some studies reporting significant deficits, but others describing preserved skills (for review, see Dawson et al., 2005, or Jemel et al., 2006; also Walsh et al., 2016). Eyetracking studies have also yielded contradictory results, with some studies indicating reduced gaze to faces (e.g. Klin et al., 2002; Nakano et al., 2010; Pelphrey et al., 2002; Tanaka and Sung, 2016) and others reporting gaze patterns to faces that are analogous to those of NT peers (Fletcher-Watson et al., 2008, 2009; McPartland et al., 2011).

There are similarly mixed findings in the literature delineating how individuals with ASD process social information from vocal cues (see McCann and Peppé, 2003, for review). Some studies show clear deficits in processing social and linguistic information from prosodic patterns (Diehl et al., 2008; Golan et al., 2007; Peppé et al., 2007). Others, however, indicate preserved abilities to perceive emotional and/or lexical signals from vocal signals (Grossman et al., 2010; Hubbard et al., 2017), although this ability deteriorates when emotional expressivity is less intense (Grossman and Tager-Flusberg, 2012). Recent data have shown that at least some of the variability in findings across vocal and facial perception may be related to the wide range in stimuli used across all studies, especially as they relate to their ecological validity (Chevallier et al., 2015). Overall, the existing literature does not indicate a blanket deficit in processing of facial and vocal social signals in ASD.

Most of this work focuses on whether autistic individuals can determine identity from faces, or read emotion from facial and vocal cues. Only a few studies have attempted to examine the way individuals with ASD process the complex social signals of first impression formation, and they have focused on the visual domain. Autistic adults with preserved cognitive and language skills reported impressions of a virtual "job applicant" that were similar to those of their NT peers (Kuzmanovic et al., 2011). Similarly, autistic children aged 5-13 looking at silent video clips of athletes during break times were as successful as their NT peers in distinguishing between athletes who were winning and those who were losing (Furley and Schweizer, 2014; Ryan et al., 2016). Kuzmanovic et al. (2011) showed that adults with ASD formed similar impressions of silent virtual characters as their NT peers, although the impressions of autistic participants were more susceptible to incongruent written information. These studies demonstrate that individuals with ASD use subtle visual signals to form first impressions from brief exposures to social information, although they leave open the question of how auditory information might affect this process. Since NT individuals use both visual and auditory information to form negative first impressions of autistic individuals (Sasson et al., 2017), and because natural social interactions typically contain simultaneous visual and auditory information, this is an important question to pursue.

The formation of social relations is crucial during adolescence and first impressions can have a significant impact on social engagement and inclusion. We therefore wanted to better understand the formation of first impressions within and across these diagnostic groups. We asked participants to provide explicit impressions of social stimuli and used eyetracking to measure implicit gaze patterns to faces during this task. We specifically chose to include both visual (facial expressions, body position, etc.) and auditory (language, prosody) information in this study, so that our stimuli mirrored the multi-modal social cues people are exposed to during day-to-day interactions. We also increased ecological validity using videos of age-matched peers, rather than computer-generated or manipulated stimuli, and by asking questions relevant to daily lives of adolescents. This study poses two fundamental questions: (1) Do adolescents with ASD form negative first impressions of age-matched peers with ASD when no diagnosis information is explicitly provided? (2) Do adolescents with and without ASD visually explore the faces of autistic versus NT peers differently? We expected this task to be more difficult for adolescents with ASD than tasks in previous studies for multiple reasons: (1) stimuli are realistic videos, rather than virtual characters, which often produce more salient social behaviors; (2) the task presented here depends on the interpretation of subtle social cues, rather than canonical emotional expressions; (3) We

provide no explicit diagnosis information about the adolescents in the videos. We therefore expect ASD participants not to differentiate their judgments or gaze patterns for peers with and without ASD. In contrast, we hypothesize that NT participants will report more negative social judgments of ASD than NT peers and will also gaze at them relatively less.

## Method

## Stimuli

We used videos of adolescents with and without ASD. During recording, we asked participants to retell an adventure story to the camera in a way that would be engaging to an imagined audience of young children. From the resulting corpus of story-retelling videos, we extracted 2 - to 4 -s-long video clips. We cut clips to include an entire phrase or sentence from beginning to end. All emotions targeted in the stories (happiness, fear, anger, and positive surprise) were represented in the clips. We rated all clips for video and audio quality and for the child's verbal production (no mispronunciations, grammatical errors, etc.) on a scale from 0 (lowest) to 3 (highest), and we excluded all clips rated below 2 . We randomly selected several angry, fearful, happy, and surprise videos of NT stimulus producers and matched them with clips of the same sentence/emotion from ASD producers, resulting in six angry, four fearful, eight happy, and six surprise video clips for a total of 24 clips in the stimulus set. The uneven numbers of emotions represented in the videos were due to fewer good-quality clips being available to match across diagnoses for some emotions.

Each clip shows the adolescents from approximately mid-chest upward, including shoulders, upper arms, and head. Adolescents in the videos were reading notes to assist their retelling of the stories from cue cards that were placed directly below the camera lens, ensuring that their gaze is directed toward the camera, albeit slightly below. The video background is a white wall flanked by two empty bookcases. Adolescents in the videos are also wearing 32 small ( 4 mm in diameter) reflective motion capture markers on their faces. We used those markers to track the movement of their facial features for a separate study. During the instructions for this study, the participants were informed about these markers and asked to ignore them. Since the markers are identical in all videos, their impact on perception and gaze patterns should be consistent across stimuli and not lead to group effects. The final stimulus set of 24 clips includes 12 videos of males with ASD and 12 videos of NT males. Seven adolescents in each diagnostic group are shown in the video clips, with no more than two videos of each person. We did not include videos of the same person saying the same phrase. Impression ratings of the same person remain stable over
multiple exposures (Sasson et al., 2017), so we did not expect two exposures to the same adolescent to affect the resulting data. For the 14 adolescents shown in the final set of stimulus videos, there were no between-group differences in non-verbal intelligent quotient (IQ; Leiter-R; Roid and Miller, 1997, ASD: $M=105.1$, NT: $M=114.6$, $F(1,13)=1.84, p=0.2)$, receptive vocabulary (Peabody Picture Vocabulary Test, Fourth Edition (PPVT-4); Dunn and Dunn, 2007, ASD: $M=119.1$, NT: $M=131.7$, $F(1,13)=1.94, p=0.19)$, or age (ASD: $M=142.1$, NT: $M=145, F(1,13)=0.03, p=0.86)$. We created two pseudorandomized stimulus sequences that were counterbalanced across participants.

## Participants

The Institutional Review Board of Emerson College approved this study and we obtained written informed consent from each participant. We recruited adolescents with and without ASD who completed the Core Language Subtests of the Clinical Evaluation of Language Fundamentals, 5th Edition (CELF-5; Semel et al., 2013) and the Kaufman Brief Intelligence Test, 2nd Edition (K-BIT-2; Kaufman and Kaufman, 2004). ASD diagnosis was confirmed via the Autism Diagnostic Observation Schedule, 2nd edition (ADOS-2; Lord et al., 2012) by administrators who achieved research reliability with a certified trainer. Participants ranged in age from 10:6 to 17:10 and the two groups (ASD: $N=22$, mean age 13:11, NT: $N=30$, mean age 13:7) were not significantly different in age $(F(1,51)=0.18, p=0.67)$, IQ $(F(1,51)=0.64$, $p=0.43$ ), language ability $(F(1,51)=0.32, p=0.57)$, or gender $\left(\chi^{2}=0.95, p=0.33\right.$; Table 1$)$.

## Procedure

Participants were led into a quiet room and seated at a comfortable viewing distance and angle from a 24 -in computer screen. All videos completely filled the screen. We explained to the participants that they would see video clips of adolescents retelling snippets from a story to clarify that the individuals in the videos did not choose the text they were saying, and to clarify that they were not speaking spontaneously. During the experimental task, all videos completely filled the screen. We asked the participants to provide first and honest impressions of the person in each clip by answering five questions using a nongraduated, continuous slider bar. The anchor points of the slider were "not likely" and "very likely" and the marker was at mid-point at the start of each question. We asked two questions about the rater's willingness to engage with the person in the video: "How likely is it that you would sit at lunch with this person?" and "How likely is it that you would start a conversation with this person?" We also asked three questions regarding the rater's assumptions

Table I. Descriptive characteristics of participant groups.

|  | ASD ( $n=22$ ), $M[95 \%$ CI $]$ | NT $(n=30), M[95 \%$ CI $]$ | Significance |
| :--: | :--: | :--: | :--: |
| Age | 13:7 [12:8,14:7] | 13:4 [12:8,14:2] | $F(1,51)=0.18, p=0.67$ |
|  | Range: 10:5-17:10 | Range: 10:6-16:10 |  |
| Sex | 18 male, 4 female | 21 male, 9 female | $\chi^{2}(1,52)=0.95, p=0.33$ |
| IQ (K-BIT-2) | I14.55 [I05.59,I23.5] | I10.77 [I05.63, I15.91] | $F(1,51)=0.64, p=0.43$ |
| Language (CELF-V) | I10.68 [I02.88, I 18.49] | I13.3 [I07.52, I 19.08] | $F(1,51)=0.32, p=0.57$ |

ASD: autism spectrum disorder; NT: neurotypical; CI: confidence interval; IQ: intelligent quotient; K-BIT-2: Kaufman Brief Intelligence Test, 2nd Edition; CELF-V: Clinical Evaluation of Language Fundamentals, 5th Edition.
about the person in the video: "How likely is it that this person gets along well with others?" "How likely is it that this person is socially awkward?" "How likely is it that this person spends a lot of time alone?" We displayed task directions on the computer screen before each video clip and verbally verified that participants understood the instructions. The five questions appeared individually on the screen after each video and participants self-paced their responses and presentation of subsequent stimuli.

## Behavioral data

We calculated the average slider response of each diagnostic group for each question using a range of -250 ("not likely") to 250 ("very likely"). For three questions, high positive slider numbers indicate higher social skills (i.e. kids in the videos are more likely to get along with others, more likely to have peers want to sit with them at lunch, or more likely to have peers want to start a conversation with them). For two questions, higher slider numbers indicate lower social skills (i.e. kids in the videos are more likely to spend time alone and more likely to be socially awkward). We therefore multiplied the slider responses to the latter two questions by -1 to normalize the polarity of responses across all five questions. All results are based on these normalized response scores. For ease of visualization, we also reversed graph labels for these two questions ("less social awkwardness" and "less social isolation") to clarify that higher scores on all questions indicate more positive evaluations.

## Eyetracking

We performed a dynamic five-point (one central point and four corners) calibration of the SensoMotoric Instruments (SMI ${ }^{\mathrm{TM}}$ ) RED eyetracker, aiming for $<1$ degree of deviation in either axis. When gaze to the first fixation point was captured, the calibration automatically proceeded to the next fixation point. We analyzed gaze data for presentation of all videos, but not for the time participants responded to the questions. We defined three areas of interest (AOIs) for each video clip: face, eyes, and mouth, using SMI software to draw AOIs for each adolescent in the stimulus video for the entire duration of each clip. We
ensured that the face AOI adhered only to the face and not the hairline or other features in the video. The eye AOI was created as a rectangle, encompassing the eyebrows and eyes. The mouth AOI was drawn as an oval to capture the entire mouth. We made frame-by-frame location and shape adjustments for all AOIs in all stimulus videos to account for whole head and feature movements (e.g. mouth opening) during speech production. The face AOI did not exclude the eye and mouth region to capture gaze to the entire face in a single AOI.

Eyetracking analysis focused on two gaze values: (1) Percent fixations for each AOI. Fixations were defined as gaze lasting a minimum of 60 ms within a maximum dispersion area of 30 pixels. This variable is expressed as a percentage of fixations to each AOI relative to the entire screen. We include this measure because it is the most commonly used metric for determining meaningful gaze patterns in this population. (2) Fixation frequency, expressed as the number of fixations per second within a given AOI. We include this measure to account for the fact that increased fixation can be constituted of frequent short or infrequent longer fixations. We visually inspected all gaze data to check for flickering, unstable, or intermittent gaze tracking and determined that data with a tracking ratio of less than $60 \%$ were not reliable enough to be included. The remaining eyetracking dataset includes 19 ASD and 29 NT participants; the two groups do not differ on language, age, IQ scores, and gender distribution (Table 2).

## Results

## Behavioral data

We conducted a 2 (diagnostic group, ASD or NT) by 2 (stimulus type, ASD or NT) by 5 (question) repeated measures analysis of variance (ANOVA) to determine overall patterns in responses to all stimuli and questions. Sphericity assumption was not met, so we are reporting results with Greenhouse-Geisser correction. Results show a main effect for stimulus type $(F(1,50)=32.55, p<0.001$, partial $\eta^{2}=0.39$ ), with both participant groups reporting higher ratings for NT stimulus videos. We also see a main effect for question $(F(2.32,116.18)=7.1, p=0.001$, partial

Table 2. Descriptive characteristics of participants included in eyetracking analysis.

|  | ASD $(n=19), M$ (SD) | NT $(n=29), M$ (SD) | Significance |
| :--: | :--: | :--: | :--: |
| Age | 13:11 [12:10,14:10] | 13:7 [12:10,14:2] | $F(1,46)=0.26, p=0.61$ |
|  | Range: 10:8-17:10 | Range: 10:6-16:10 |  |
| Sex | 15 male, 4 female | 21 male, 8 female | $\chi^{2}(1,48)=0.26, p=0.61$ |
| IQ (K-BIT-2) | 116.63 [107.01,126.25] | 110.17 [104.99,115.35] | $F(1,46)=1.78, p=0.19$ |
| Language (CELF-V) | 113.05 [104.51,121.59] | 112.76 [106.88,118.64] | $F(1,46)=0.004, p=0.95$ |

ASD: autism spectrum disorder; NT: neurotypical; SD: standard deviation; IQ: intelligent quotient; K-BIT-2: Kaufman Brief Intelligence Test, 2nd Edition; CELF-V: Clinical Evaluation of Language Fundamentals, 5th Edition.
$\eta^{2}=0.12$ ). There is no main effect for participant diagnosis $(F(1,50)=2.11, p=0.15$, partial $\eta^{2}=0.04)$, but a significant question-by-diagnosis interaction $(F(2.32,116.18)=3.78$, $p=0.02$, partial $\eta^{2}=0.07$ ). To verify that participants' responses did not change based on seeing some of the adolescents in the videos a second time, we conducted the same analysis using data from only the first video clip of each stimulus producer. Results of ratings based on this stimulus set show the same pattern. There is a main effect for stimulus type $(F(1,50)=21.77, p<0.001$, partial $\eta^{2}=0.3$ ) and a main effect for question $(F(2.39,119.57)=6.45, p=0.001$, partial $\eta^{2}=0.12)$. There is no main effect for participant diagnosis $(F(1,50)=2.47$, $p=0.12$, partial $\eta^{2}=0.05$ ), but a significant question-bydiagnosis interaction $(F(2.39,119.57)=3.57, p=0.02$, partial $\eta^{2}=0.07$ ). All subsequent analyses are therefore based on the full dataset, to maximize available power.

To better understand the patterns of main effects and interactions, we divided questions into two categories: (1) Questions about participants' perception of others ("person gets along with others," "person is socially awkward," and "person spends a lot of time alone") and (2) Questions about participants' willingness to interact with others ("I would sit at lunch with that person" and "I would start a conversation with that person").

Questions about others. A 2 (diagnostic group, ASD or NT) by 2 (stimulus type, ASD or NT) by 3 (question) repeated measures ANOVA reveals a main effect for stimulus type $(F(1,50)=34.41, p<0.001$, partial $\eta^{2}=0.41)$, with both participant groups reporting higher ratings for NT stimulus videos. We also see a main effect for question $(F(1.74,100)=6.32, p=0.004$, partial $\eta^{2}=0.11)$, with the lowest ratings for both stimulus types given for the question of social awkwardness. There is a main effect for participant diagnosis $(F(1,50)=4.79, p=0.03$, partial $\eta^{2}=0.09)$, with the NT group providing higher ratings overall. We also find a significant question-by-diagnosis interaction $(F(1.74,100)=4.58, p=0.017$, partial $\eta^{2}=0.08)$.

To follow up on this interaction, we conducted a oneway ANOVA with participant diagnosis as the betweengroup variable. It reveals that ASD participants judge adolescents in both stimulus types significantly more
negatively than do NT participants on the questions of social awkwardness (ASD stimuli: $F(1,51)=8.2, p=0.006$; NT stimuli: $F(1,51)=4.9, p=0.032$ ) and spending time alone (ASD stimuli: $F(1,51)=6.3, p=0.016$; NT stimuli: $F(1,51)=4.2, p=0.045)$. There is no significant difference between the groups on judgments of whether adolescents in the videos get along well with others (ASD stimuli: $F(1,51)=0.36, \quad p=0.55 ; \quad$ NT stimuli: $F(1,51)=0.12$, $p=0.73$; Figure 1).

In both participant groups, ratings of social awkwardness and social isolation (spends time alone) are significantly positively correlated for both stimulus types (all correlation data in Table 3). Interestingly, the NT participants provide ratings for gets along with others that are highly correlated with ratings of less social awkwardness and less social isolation for both stimulus types (ASD gets along with ASD socially awkward: $r=0.75, N=30$, $p<0.0001$; ASD gets along with ASD social isolation: $r=0.73, N=30, p<0.0001 ; N T$ gets along with NT socially awkward: $r=0.63, N=30, p<0.0001 ; N T$ gets along with NT social isolation: $r=0.72, N=30, p<0.0001$ ). In contrast, ratings from ASD participants on these questions are not correlated (ASD gets along with ASD less socially awkward: $r=0.26, N=22, p=0.25$; ASD gets along with ASD less social isolation: $r=0.25, N=22, p=0.27$; NT gets along with NT less socially awkward: $r=0.29, N=22$, $p=0.19 ; N T$ gets along with NT less social isolation: $r=0.13, N=22, p=0.57$ ); see Figure 2.

Questions about willingness for own engagement. A 2 (diagnostic group, ASD or NT) by 2 (stimulus type, ASD or NT) by 2 (questions about self-engagement) repeated measures ANOVA reveals a main effect for stimulus type $(F(1,50)=23.55, p<0.001$, partial $\eta^{2}=0.32)$, with all participants providing higher ratings of videos showing NT adolescents. There are no main effect for question or diagnosis and no question-by-type, or type-by-diagnosis, interaction.

## Eyetracking data

To determine overall visual attention to the task for the two groups, we investigated percent fixation to the parts of the

![img-0.jpeg](img-0.jpeg)

Figure I. Average ratings for all questions.
These graphs present the average rating data, ranging from -32 to 65 , in contrast to the full range of raw rating data based on the $\pm 250$ range available to participants.
screen that do not contain social information (i.e. everything but the face) using a two-tailed, independent groups $t$-test. Results show that participants with ASD $(M=13.06$, $\mathrm{SD}=10.22$ ) gaze less at the non-social screen than NT participants $(M=21.31, \mathrm{SD}=14.08, t(46)=2.2, p=0.033)$. We therefore calculated fixations to the social AOIs (eyes, mouth, face) as a proportion of each participant's gaze to the overall screen. Since the mouth and eye AOIs overlap with the face AOI, we conducted the analysis for the face AOI separately.

Percent fixation. For the face AOI, we used a 2 (participant group) by 2 (stimulus type) repeated measures ANOVA for
percent fixation and fixation frequency. Results show a main effect for stimulus type $(F(1,46)=30.31, p<0.0001)$ with both groups gazing less at the faces of ASD adolescents. There is no main effect for participant diagnosis $(F(1,46)=1.21, p=0.28)$ and no stimulus type-by-diagnosis interaction $(F(1,46)=1.69, p=0.2)$.

We also conducted a 2 (participant group) by 2 (stimulus type) by 2 (AOI: mouth, eyes) repeated measures ANOVA for percent fixation and fixation frequency. The sphericity assumption is not met, so we present results with Greenhouse-Geisser correction. Results show a main effect for stimulus type $(F(1,46)=10.28, p=0.002$, partial $\eta^{2}=0.18$ ) with less gaze to ASD stimuli and a main effect

![img-1.jpeg](img-1.jpeg)

![img-2.jpeg](img-2.jpeg)

Figure 2. Correlations of ratings across questions.

| Percent Fixation |  |  |  |  |  |  |
| :--: | :--: | :--: | :--: | :--: | :--: | :--: |
|  |  |  |  |  |  |  |
|  |  |  |  |  |  |  |
|  | Eyes of ASD | Eyes of NT | Mouth of ASD | Mouth of NT | Face of ASD | Face of NT |
| - ASD Participants | 2.3797 | 3.0460 | 3.6515 | 6.3029 | 17.5816 | 23.1769 |
| - NT Participants | 3.4099 | 5.3205 | 5.5471 | 8.2468 | 23.0636 | 32.5845 |
| Error bars are Standard Error |  |  |  |  |  |  |

Figure 3. Gaze data for all stimulus types.
for $\operatorname{AOI}(F(1,46)=22.71, p<0.0001)$, with both groups fixating more on the mouth than the eye AOI. There is no effect for the diagnostic group $(F(1,46)=1.98, p=0.17$, partial $\eta^{2}=0.04$ ). To follow up on the main effect for stimulus type, we conducted paired $t$-tests with a Bonferroni adjusted alpha level of 0.017 . Results show higher fixation percentage to the eyes $(t(48)=3.3, p=0.002)$, face $(t(48)=5.86, p<0.0001)$, and mouth $(t(48)=3.86$, $p<0.0001$ ) of NT versus ASD videos (Figure 3).

Fixation frequency. The 2 (group) by 2 (stimulus type) repeated measures ANOVA for the face AOI shows a main effect for stimulus type $(F(1,46)=28.39, p<0.0001$, partial $\eta^{2}=0.38$ ), but no main effect for diagnosis $(F(1,46)=2.49, p=0.12$, partial $\eta^{2}=0.05)$.

The 2 (group) by 2 (stimulus type) by 2 (AOI: eyes, mouth) repeated measures ANOVA reveals a main effect for stimulus type $(F(1,46)=9.02, p=0.004$, partial $\eta^{2}=0.16$ ) and a main effect for AOI $(F(1,46)=18.72$, $p<0.0001$, partial $\eta^{2}=0.29$ ), with both groups having higher fixation frequency to the mouth than the eyes. There
is also a marginal main effect for diagnosis $(F(1,46)=3.92$, $p=0.05$, partial $\eta^{2}=0.078$ ), with the NT cohort having significantly higher fixation frequency to both AOIs than ASD participants. Post hoc paired $t$-tests to investigate stimulus type ( $\alpha$ set at 0.017 ) show significantly greater fixation frequency in both participant cohorts to the face $(t(48)=5.63, p<0.0001)$ and mouth $(t(48)=3.6, p=0.001)$, but not the eyes $(t(48)=2.19, p=0.03)$ of NT versus ASD videos.

## Discussion

We predicted that NT participants would rate NT peers in videos more highly than they rated ASD peers and would look at the faces of NT peers more than at the faces of ASD peers. We also predicted that ASD participants would not differentiate between peers with and without ASD in either judgment formation or gaze patterns. The data confirm our hypotheses about the NT, but not the ASD cohort. As predicted, NT participants rated NT peers in videos more favorably than they rated peers with ASD across all five

questions and also looked more at the faces of NT than ASD peers. Counter to our predictions, however, ASD participants also showed preferential looking to NT faces and rated NT peers more favorably. On questions related to their assessment of others' social skills, particularly ASD participants even rated adolescents with ASD more harshly than NT participants did.

While unexpected, these results are partially supported by recent data showing that ASD and NT children had similar accuracy rates for identifying emotional expressions of ASD and NT adults (Brewer et al., 2016). Similarly, Hubbard et al. (2017) found that both NT and ASD adults judged ASD speakers' emotional speech to be less natural, despite more clearly expressing the emotion. In another study, a small sample of adults with ASD were asked to judge whether virtual, animated "job applicants" exhibited dominant, neutral, or submissive attitudes (Schwartz et al., 2014). Similar to our results, participants with ASD were as capable as their NT peers of providing judgments based on social cues from the stimuli. However, in contrast to our findings, adults with ASD judged the characters more positively than did NT adults. The difference between our findings and the ones reported by Schwartz et al. may depend on many factors, including the fact that our stimuli consisted of videos of real adolescents with and without ASD, while theirs presented virtual characters whose expressions are often simplified, making them potentially more salient to individuals with ASD (Rosset et al., 2008). Task demands in each study also focused on different social attributes in different social contexts. Still, both sets of results confirm an important finding that adolescents and adults with ASD are able to extract subtle social cues from exposures as brief as a few seconds.

These data highlight the saliency of social signal differences found in facial and vocal expressions of ASD adolescents. There are several studies showing that expressive prosody of individuals with ASD is marked by unusual patterns in pitch, dynamic range, and rhythm (e.g. Diehl and Paul, 2013; Grossman and Tager-Flusberg, 2012; Grossman et al., 2010; Hubbard et al., 2017; Peppé et al., 2007 for review). Performing acoustic analyses of these prosodic metrics allows for objective interpretation of autistic vocal signals that could be foundational to the fact that this cohort is perceived as "awkward" (Bone et al., 2015). Objective analyses of facial expressions are more difficult to perform, since it often depends on a time-intensive process whereby human coders who have undergone extensive training identify subtle facial movement patterns (Ekman and Friesen, 1978; Sato and Yoshikawa, 2007). This makes it impractical to perform large-scale, objective analyses of facial movements in ASD. One possible alternative is to use facial motion capture to quantify facial feature movement during dynamic expressions. The stimuli used in this study contain videos
of several individuals repeating different sentences expressing a variety of emotions. The resulting variability in the facial movements across stimuli combined with the small number of samples per participant does not allow for a meaningful motion capture analysis of the facial expressions produced in this stimulus set. However, we have successfully used facial motion capture to investigate a larger dataset of mimicked facial expressions of ASD and NT adolescents from the same cohort, including the adolescents who produced the stimulus videos. Our analyses of those data show higher levels of asynchrony between movements of facial regions (Metallinou et al., 2013) and reduced complexity of dynamic facial feature movements in adolescents with ASD (Guha et al., 2016). Although these findings do not directly correspond to the stimuli used in this study, they do provide some insight into the underlying differences between the facial movement patterns of the autistic versus NT adolescents in the videos. These differences may have contributed to participants' higher ratings of and increased gaze to videos of NT adolescents. Further investigation into facial feature movements of individuals with ASD is needed to better understand the underlying causes of social deficits that seem salient from brief exposures.

The finding that both participant groups perceive subtle social cues of ASD expressions is particularly interesting when viewed in combination with our eyetracking data, which show that both participant groups looked less at ASD than NT adolescents. This finding was consistent across all three gaze measures, showing that adolescents with ASD do not differ from their NT peers in the frequency or amount of fixations to these stimuli. The social motivation hypothesis of ASD (Chevallier et al., 2012; Dawson, 2008; Dawson et al., 2005) suggests that the social impairments of individuals with ASD may be caused by an early lack of interest in and visual attention to social stimuli, including faces. This lack of interest is proposed to lead to a reduced expertise in producing and processing social cues. Our data do not support this claim, since adolescents with ASD in our study did not show either decreased looking to faces overall or decreased expertise at decoding social cues from these stimuli.

When looking at correlations between rating data, the NT cohort shows a significant correlation between responses to the question of whether a person gets along well with others and whether they spend time alone. Interestingly, the ASD cohort does not show this correlation, indicating that ASD adolescents do not assume that social ability (getting along well with others) entails social interaction (not spending their time alone). Based on these limited data, it is possible to speculate that, from the perspective of an autistic person, the desire to spend a lot of time with other people may not depend on an ability to get along with others and vice versa. These data align with findings showing that adults with ASD often express a desire for better quality interactions with friends

and family, but not more frequent interactions (Van Asselts-Goverts et al., 2015). Despite reporting higher incidents of loneliness than adult NT peers (Sasson et al., 2017), ASD individuals may not see frequent interactions with friends as an important or necessary aspect of social integration.

Our results show that both participant groups fixated more and more frequently to the mouth region of the face, rather than the eyes. This result contrasts with previous literature suggesting that individuals with ASD show pervasive preference for mouth-directed gaze (Falck-Ytter et al., 2013) that is different from the eye-directed gaze of NT individuals (Tanaka and Sung, 2015). However, recent reviews of eyetracking literature suggest that gaze patterns of autistic individuals to faces may not reflect a rigid diag-nosis-based (ASD vs NT) difference, but instead are strongly dependent on the nature of the stimuli and the specifics of the task demands (Chita-Tegmark, 2016; Falck-Ytter and Von Hofsten, 2011; Guillon et al., 2014). In the case of our study, it is likely that both participant groups looked at the mouths more because the speech movements attracted visual attention. In addition, both participant groups may have gazed less at the eyes because individuals in the stimulus videos were not looking directly into the camera. As described in the methods, adolescents in the videos were reading cue cards, which were held directly below the recording camera. This resulted in stimulus producers gazing slightly below the camera. This may have reduced the pressures of direct eye gaze on participants with ASD in our study and made the gaze patterns of the two cohorts more comparable. Even if videos had shown adolescents looking directly at participants, it is possible that gaze patterns would still be similar across groups simply because pre-recorded videos do not provide the same social pressures as live interactions. It is therefore important to push the field further into developing live-viewing eyetracking paradigms for older children and adults in interactive social contexts (Guillon et al., 2014).

## Limitations

These data are based on a relatively small sample of adolescents and cannot be generalized without replication. It is also important to consider that the videos we asked participants to rate were based on elicited retellings of stories with adolescents in the videos, rather than live interactions. Stimulus producers in the videos were also wearing motion capture markers. Given that all these factors apply to videos of children with and without ASD, they should not have caused differences in how videos of either group of stimulus producers were perceived by participants. Nevertheless, future studies should focus on videos captured during natural conversations, rather than elicited narratives, and present individuals without reflective markers on their faces.

## Conclusion

Although it is somewhat encouraging that ASD adolescents in our study were able to "read" the subtle social cues that may mark their own expressions as more socially awkward and less socially capable, the fact that individuals with ASD are perceived negatively not only by NT peers, but also by peers who share their diagnosis could have significant repercussions for the success of their social interactions. Importantly, participants' negative social perceptions and unwillingness to engage are not merely present in explicit responses to judgment questions, but are even reflected implicitly, in relatively reduced face-directed gaze to adolescents with ASD by both participant groups. Given the oft-reported desire of individuals with ASD to interact with and support each other, as well as the need to facilitate better integration between ASD and NT individuals, these data highlight the importance of creating intentional spaces where information about diagnosis is shared so that such interactions can be fostered and encouraged. Otherwise, if left to chance encounters in school lunchrooms, both autistic and NT adolescents may perpetuate the social rejection of this group.

## Acknowledgements

We thank Dr Rhiannon Luyster for her very helpful insights about these data and Kayla Neumeyer for introducing us to the writings of autistic adults. We are grateful to the children and families who dedicated their time to participate in our research.

## Declaration of conflicting interests

The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.

## Funding

The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported through Grants NIH-NIDCD 1R01DC012774 and NIH-NIDCDR21DC010867.

## Note

1. In the clinical literature, person-first language is preferred. However, many individuals with ASD prefer the term autistic adult/child. To reflect this dichotomy, we use the two terminologies interchangeably.

## References

Ambady N and Skowronski JJ (2008) First Impressions. New York: Guilford Press.
Berns AJ (2016) Perceptions and Experiences of Friendship and Loneliness in Adolescent Males with High Cognitive Ability and Autism Spectrum Disorder. Iowa City, IA: The University of Iowa.

Bone D, Black MP, Ramakrishna A, et al. (2015) Acousticprosodic correlates of "awkward" prosody in story retellings from adolescents with autism. In: Proceedings of the annual conference of the international speech communication association, INTERSPEECH. Available at: https://sail. usc.edu/ dbone/Bone_acousticProsidicAwkwardProsody_ Interspeech_2015.pdf
Brewer R, Biotti F, Catmur C, et al. (2016) Can neurotypical individuals read autistic facial expressions? Atypical production of emotional facial expressions in autism spectrum disorders. Autism Research 9(2): 262-271.
Chevallier C, Kohls G, Troiani V, et al. (2012) The social motivation theory of autism. Trends in Cognitive Sciences 16(4): $231-239$.
Chevallier C, Parish-Morris J, McVey A, et al. (2015) Measuring social attention and motivation in autism spectrum disorder using eye-tracking: stimulus type matters. Autism Research 8(5): 620-628.
Chita-Tegmark M (2016) Attention allocation in ASD : a review and meta-analysis of eye-tracking studies. Review Journal of Autism and Developmental Disorders 48: 209-223.
Dawson G (2008) Early behavioral intervention, brain plasticity, and the prevention of autism spectrum disorder. Development and Psychopathology 20(3): 775-803.
Dawson G, Webb SJ and McPartland J (2005) Understanding the nature of face processing impairment in autism: insights from behavioral and electrophysiological studies. Developmental Neuropsychology 27(3): 403-424.
Diehl JJ and Paul R (2013) Acoustic and perceptual measurements of prosody production on the PEPS-C by children with autism spectrum disorders. Applied Psycholinguistics 34(1): 135-161.
Diehl JJ, Bennetto L, Watson D, et al. (2008) Resolving ambiguity: a psycholinguistic approach to understanding prosody processing in high-functioning autism. Brain and Language 106(2): 144-152.
Dunn DM and Dunn LM (2007) Peabody Picture Vocabulary Test: Manual. New York: Pearson.
Ekman P and Friesen WV (1978) The Facial Action Coding System: A Technique for the Measurement of Facial Movement. Palo Alto, CA: Consulting Psychologists Press.
Falck-Ytter T and Von Hofsten C (2011) How Special Is Social Looking in ASD. A Review. Progress in Brain Research, vol. 3. 1st ed. Amsterdam: Elsevier B.V.
Falck-Ytter T, Bölte S and Gredebäck G (2013) Eye tracking in early autism research. Journal of Neurodevelopmental Disorders 5(1): 28.
Faso D, Sasson N and Pinkham A (2015) Evaluating posed and evoked facial expressions of emotion from adults with autism spectrum disorder. Journal of Autism and Developmental Disorders 45(1): 75-89.
Fletcher-Watson S, Findlay JM, Leekam SR, et al. (2008) Rapid detection of person information in a naturalistic scene. Perception 37(4): 571-583.
Fletcher-Watson S, Leekam SR, Benson V, et al. (2009) Eyemovements reveal attention to social information in autism spectrum disorder. Neuropsychologia 47(1): 248-257.
Furley P and Schweizer G (2014) The expression of victory and loss: estimating who's leading or trailing from nonverbal cues in sports. Journal of Nonverbal Behavior 38(1): 13-29.

Golan O, Baron-Cohen S, Hill J, et al. (2007) The "Reading the Mind in the Voice" test-revised: a study of complex emotion recognition in adults with and without autism spectrum conditions. Journal of Autism and Developmental Disorders 37(6): 1096-1106.
Grossman RB (2015) Judgments of social awkwardness from brief exposure to children with and without high-functioning autism. Autism : The International Journal of Research and Practice 19(5): 590-587.
Grossman RB and Tager-Flusberg H (2012a) Quality matters! Differences between expressive and receptive non-verbal communication skills in adolescents with ASD. Research in Autism Spectrum Disorders 6(3): 1150-1155.
Grossman RB and Tager-Flusberg H (2012b) "Who said that?" Matching of low- and high-intensity emotional prosody to facial expressions by adolescents with ASD. Journal of Autism and Developmental Disorders 42(12): 2546-2557.
Grossman RB, Bemis RH, Skwerer DP, et al. (2010) Lexical and affective prosody in children with high-functioning autism. Journal of Speech, Language, and Hearing Research 53(3): 778-793.
Guha T, Yang Z, Grossman RB, et al. (2016) A computational study of expressive facial dynamics in children with autism. IEEE Transactions on Affective Computing 9: 14-20.
Guillon Q, Hadjikhani N, Baduel S, et al. (2014) Visual social attention in autism spectrum disorder: insights from eye tracking studies. Neuroscience and Biobehavioral Reviews 42: 279-297.
Hubbard DJ, Faso DJ, Assmann PF, et al. (2017) Production and perception of emotional prosody by adults with autism spectrum disorder. Autism Research 10(12): 1991-2001.
Iobst E, Nabors L, Rosenzweig K, et al. (2009) Adults' perceptions of a child with autism. Research in Autism Spectrum Disorders 3(2): 401-408.
Jemel B, Mottron L and Dawson M (2006) Impaired face processing in autism: fact or artifact? Journal of Autism and Developmental Disorders 36(1): 91-106.
Kaufman A and Kaufman N (2004) Manual for the Kaufman Brief Intelligence Test. 2nd ed. Circle Pines, MN: American Guidance Service.
Klin A, Jones W, Schultz R, et al. (2002) Visual fixation patterns during viewing of naturalistic social situations as predictors of social competence in individuals with autism. Archives in General Psychiatry 59(9): 809-816.
Komeda H (2015) Similarity hypothesis: understanding of others with autism spectrum disorders by individuals with autism spectrum disorders. Frontiers in Human Neuroscience 9: 124 .
Kuzmanovic B, Schilbach L, Lehnhardt FG, et al. (2011) A matter of words: impact of verbal and nonverbal information on impression formation in high-functioning autism. Research in Autism Spectrum Disorders 5(1): 604-613.
Lord C, Rutter M, DiLavore PC, et al. (2012) Autism diagnostic observation schedule, second edition: ADOS-2. Manual (Part 1): Modules 1-4. Torrance, CA: Western Psychological Services.
Maïano C, Normand CL, Salvas M-C, et al. (2016) Prevalence of school bullying among youth with autism spectrum disorders: A systematic review and meta-analysis. Autism Research 9(6): 601-615.

McCann J and Peppé S (2003) Prosody in autism spectrum disorders: a critical review. International Journal of Language \& Communication Disorders 38(4): 325-350.
McPartland JC, Webb SJ, Keehn B, et al. (2011) Patterns of visual attention to faces and objects in autism spectrum disorder. Journal of Autism and Developmental Disorders 41(2): $148-157$.
Metallinou A, Grossman RB and Narayanan S (2013) Quantifying atypicality in affective facial expressions of children with autism spectrum disorders. ProceedingsIEEE International Conference on Multimedia and Expo 2013: 1-6.
Milton DEM (2012) On the ontological status of autism: the "double empathy problem." Disability \& Society 27(6): 883-887.
Nakano T, Tanaka K, Endo Y, et al. (2010) Atypical gaze patterns in children and adults with autism spectrum disorders dissociated from developmental changes in gaze behaviour. Proceedings of the Royal Society B: Biological Sciences 277(1696): 2935-2943.
Pelphrey KA, Sasson NJ, Reznick JS, et al. (2002) Visual scanning of faces in autism. Journal of Autism and Developmental Disorders 32(4): 249-261.
Peppé S, McCann J, Gibbon FO', et al. (2007) Receptive and expressive prosodic ability in children with high-functioning autism. Journal of Speech Language and Hearing Research 50(4): 1015-1028.
Roid GH and Miller LJ (1997) Leiter International Performance Scale-Revised. Wood Dale, IL: Stoelting Co.
Rosset D, Rondan C, Da Fonseca D, et al. (2008) Typical emotion processing for cartoon but not for real faces in children with autistic spectrum disorders. Journal of Autism and Developmental Disorders 38(5): 919-925.
Ryan C, Furley P and Mulhall K (2016) Judgments of nonverbal behaviour by children with high-functioning autism spectrum disorder: can they detect signs of winning and losing from brief video clips? Journal of Autism and Developmental Disorders 46(9): 2916-2923.
Sasson NJ and Morrison KE (2017) First impressions of adults with autism improve with diagnostic disclosure and increased autism knowledge of peers. Autism. Epub ahead of print 17 October. DOI: 10.1177/1362361317729526.
Sasson NJ, Faso DJ, Nugent J, et al. (2017) Neurotypical peers are less willing to interact with those with autism based on thin slice judgments. Scientific Reports 7: 1-10. Available at: https://www.nature.com/articles/srep40700.pdf
Sato W and Yoshikawa S (2007) Spontaneous facial mimicry in response to dynamic facial expressions. Cognition 104(1): 1-18.

Schroeder JH, Cappadocia MC, Bebko JM, et al. (2014) Shedding light on a pervasive problem: A review of research on bullying experiences among children with autism spectrum disorders. Journal of Autism \& Developmental Disorders 44(7): $1520-1534$.
Schwartz C, Dratsch T, Vogeley K, et al. (2014) Brief report: Impression formation in high-functioning autism: Role of nonverbal behavior and stereotype activating information. Journal of Autism and Developmental Disorders 44(7): 1759-1765.
Semel E, Wiig EH and Secord WA (2013) Clinical Evaluation of Language Fundamentals-5. Bloomington, MN: NCS Pearson, Inc.
Shtayermman O (2009) An exploratory study of the stigma associated with a diagnosis of Asperger's syndrome: the mental health impact on the adolescents and young adults diagnosed with a disability with a social nature. Journal of Human Behavior in the Social Environment 19(3): 298-313.
Sinclair J (2010) Being autistic together. Disability Studies Quarterly 30(1). Available at: http://www.dsq-sds.org/article/view/1075/1248
Stagg SD, Slavny R, Hand C, et al. (2014) Does facial expressivity count? How typically developing children respond initially to children with autism. Autism 18(6): 704-711.
Swaim KF and Morgan SB (2001) Children's attitudes and behavioral intentions toward a peer with autistic behaviors: does a brief educational intervention have an effect? Journal of Autism and Developmental Disorders 31(2): 195-205.
Tanaka JW and Sung A (2015) Impaired face processing in autism: fact or artifact? Journal of Autism and Developmental Disorders 46(5): 1538-1552.
Tanaka JW and Sung A (2016) The "eye avoidance" hypothesis of autism face processing. Journal of Autism and Developmental Disorders 46(5): 1538-1552.
Taylor JL and Seltzer MM (2011) Employment and post-secondary educational activities for young adults with autism spectrum disorders during the transition to adulthood. Journal of Autism and Developmental Disorders 41(5): 566-574.
Van Asselts-Goverts AE, Embregts PJCM, Hendriks AHC, et al. (2015) Do social networks differ? Comparison of the social networks of people with intellectual disabilities, people with autism spectrum disorders and other people living in the community. Journal of Autism and Developmental Disorders 45: 1191-1203.
Walsh JA, Creighton SE and Rutherford MD (2016) Emotion perception or social cognitive complexity: what drives face processing deficits in autism spectrum disorder? Journal of Autism and Developmental Disorders 46(2): 615-623.